prompts:
  prompt: &prompt |-
    [Question]
    ${source_text}
    [The Start of Assistant 1’s Answer]
    ${compared_text_one}
    [The End of Assistant 1’s Answer]
    [The Start of Assistant 2’s Answer]
    ${compared_text_two}
    [The End of Assistant 2’s Answer]
    [System]
    We would like to request your feedback on the performance of two AI assistants in response to the user question displayed above.
    Please consider the helpfulness, relevance, accuracy, and level of detail of their responses.
    There are a few other referee assigned the same task, it's your responsibility to discuss with them and think critically before you make your final judgement.
    Each assistant receives an overall score on a scale of 1 to 10, where a higher score indicates better overall performance.

    Here is your discuss history:
    ${chat_history}

    ${role_description}

    Now it's your time to talk, please make your talk short and clear, ${agent_name} !

    ${final_prompt}


environment:
  env_type: llm_eval
  max_turns: 6
  rule:
    order:
      type: sequential
    visibility:
      type: all
    selector:
      type: basic
    updater:
      type: basic
    describer:
      type: basic

agents:
  -
    agent_type: llm_eval_multi
    name: Sports Fan
    final_prompt_to_use: |-
      Please first provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.
      Then, output two lines indicating the scores for Assistant 1 and 2, respectively.

      Remember that you are not required to output the same value as other referees !
      Output with the following format strictly:
      Evaluation evidence: [your explanation here]
      The score of Assistant 1: [score only]
      The score of Assistant 2: [score only]
    role_description: |-
      You are the Sports Fan, one of the referees in this task. You have a deep passion for the game and are knowledgeable about the strategies and techniques used in sports. Please help others determine which response effectively captures the excitement and significance of the winning play.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-3.5-turbo-0301"
      llm_type: gpt-3.5-turbo-0301
      temperature: 0
      max_tokens: 512
  -
    agent_type: llm_eval_multi
    name: Coach
    final_prompt_to_use: |-
      Please first provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.
      Then, output two lines indicating the scores for Assistant 1 and 2, respectively.

      Remember that you are not required to output the same value as other referees !
      Output with the following format strictly:
      Evaluation evidence: [your explanation here]
      The score of Assistant 1: [score only]
      The score of Assistant 2: [score only]
    role_description: |-
      You are the Coach, one of the referees in this task. You have extensive experience in coaching and analyzing gameplays. Your expertise lies in understanding the tactical decisions made by players and their impact on the outcome of the game. Please help others determine which response provides the most accurate and insightful analysis of the winning play.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-3.5-turbo-0301"
      llm_type: gpt-3.5-turbo-0301
      temperature: 0
      max_tokens: 512
      
  -
    agent_type: llm_eval_multi
    name: Statistician
    final_prompt_to_use: |-
      Please first provide a comprehensive explanation of your evaluation, avoiding any potential bias and ensuring that the order in which the responses were presented does not affect your judgment.
      Then, output two lines indicating the scores for Assistant 1 and 2, respectively.

      Remember that you are not required to output the same value as other referees !
      Output with the following format strictly:
      Evaluation evidence: [your explanation here]
      The score of Assistant 1: [score only]
      The score of Assistant 2: [score only]
    role_description: |-
      You are the Statistician, one of the referees in this task. You have a strong background in analyzing data and interpreting statistics related to sports. Your role is to evaluate the responses based on the statistical significance of the winning play and its impact on the overall game. Please help others determine which response presents the most compelling statistical evidence supporting the winning play.
    memory:
      memory_type: chat_history
    memory_manipulator:
      memory_manipulator_type: basic
    prompt_template: *prompt
    llm:
      model: "gpt-3.5-turbo-0301"
      llm_type: gpt-3.5-turbo-0301
      temperature: 0
      max_tokens: 512

tools: ~